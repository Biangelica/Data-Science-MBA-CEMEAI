{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzh0phpKFC5gTrQCC42QrN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Biangelica/Data-Science-MBA-CEMEAI/blob/main/Introdu%C3%A7%C3%A3o%20a%20Ci%C3%AAncia%20de%20Dados/Aula%206/Prova_Aula_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considere a base de dados winequality-red.csv. Selecione os melhores hiperarâmetros do método k-vizinhos usando o método GridSearchCV.\n",
        "\n",
        "Use:\n",
        "\n",
        "hparameters = {'n_neighbors': range(1,11),\n",
        "\n",
        "              'metric': ['euclidean', 'cityblock', 'cosine', 'manhattan', 'minkowski'],\n",
        "              'weights':['uniform', 'distance']\n",
        "             }\n",
        "\n",
        "E faça a padronização dos dados:\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "Considere 80% dos dados no conjunto de treinamento e 20% no teste.\n",
        "\n",
        "Qual a acurácia obtida?"
      ],
      "metadata": {
        "id": "TT-P_x6k0yqv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dD-KbS50xBP",
        "outputId": "358fcbf9-46bb-4c16-88dc-62652501320e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores hiperparâmetros: {'metric': 'cosine', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "Acurácia: 0.675\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# Carregar a base de dados\n",
        "data = pd.read_csv('winequality-red.csv')\n",
        "\n",
        "# Separar os dados em X (atributos) e y (rótulos)\n",
        "X = data.drop('quality', axis=1)\n",
        "y = data['quality']\n",
        "\n",
        "# Dividir os dados em conjunto de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Padronizar os dados\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definir os hiperparâmetros para GridSearchCV\n",
        "hparameters = {'n_neighbors': range(1, 11),\n",
        "               'metric': ['euclidean', 'cityblock', 'cosine', 'manhattan', 'minkowski'],\n",
        "               'weights': ['uniform', 'distance']\n",
        "              }\n",
        "\n",
        "# Criar o modelo KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Aplicar GridSearchCV para encontrar os melhores hiperparâmetros\n",
        "grid_search = GridSearchCV(knn, hparameters, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Melhores hiperparâmetros encontrados\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Treinar o modelo com os melhores hiperparâmetros\n",
        "best_knn = KNeighborsClassifier(**best_params)\n",
        "best_knn.fit(X_train, y_train)\n",
        "\n",
        "# Prever os rótulos para o conjunto de teste\n",
        "y_pred = best_knn.predict(X_test)\n",
        "\n",
        "# Calcular a acurácia\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Melhores hiperparâmetros:\", best_params)\n",
        "print(\"Acurácia:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repita a classificação do exemplo anterior, mas agora considere uma floresta aleatória. Use:\n",
        "\n",
        "hparameters = {\n",
        "    'n_estimators': [10, 25, 100],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth' : [4,5,6,7,8],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}   \n",
        "\n",
        "Qual a acurácia obtida?"
      ],
      "metadata": {
        "id": "8xAEbp_i3Z-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Carregar o dataset\n",
        "data = pd.read_csv('winequality-red.csv')\n",
        "\n",
        "# Separar features (X) e target (y)\n",
        "X = data.drop('quality', axis=1)\n",
        "y = data['quality']\n",
        "\n",
        "# Dividir os dados em conjunto de treinamento e teste (80% treino, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Padronizar os dados\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definir os hiperparâmetros para GridSearchCV\n",
        "hparameters = {\n",
        "    'n_estimators': [10, 25, 100],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth' : [4, 5, 6, 7, 8],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Criar o classificador RandomForest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Criar o objeto GridSearchCV\n",
        "grid_search = GridSearchCV(rf, hparameters, cv=5, scoring='accuracy')\n",
        "\n",
        "# Treinar o modelo usando GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Melhores hiperparâmetros\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Melhores hiperparâmetros encontrados:\")\n",
        "print(best_params)\n",
        "\n",
        "# Melhor modelo com os melhores hiperparâmetros\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "# Predizer os valores de teste\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Calcular a acurácia\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Acurácia obtida:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR3CNJK-3Ztt",
        "outputId": "127f9142-d594-45df-b384-f54e512a8b39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores hiperparâmetros encontrados:\n",
            "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "Acurácia obtida: 0.60625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quando ocorre overfitting?\n",
        "\n",
        "3 )\n",
        "\n",
        "a.\n",
        "Quando os dados estão correlacionados.\n",
        "\n",
        "\n",
        "b.\n",
        "Quando há um super ajuste do modelo ao conjunto de teste.\n",
        "\n",
        "\n",
        "c.\n",
        "Quando o modelo é capaz de predizer muito bem o conjunto de treinamento, mas não consegue predizer os valores no conjunto de teste.\n",
        "\n",
        "\n",
        "d.\n",
        "Quando os dados estão desbalanceados e há mais dados em uma classe do que outra.\n",
        "\n",
        "\n",
        "e.\n",
        "Quando os dados contêm muito ruído."
      ],
      "metadata": {
        "id": "oYrBLfY64tVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Quando há um super ajuste do modelo ao conjunto de teste."
      ],
      "metadata": {
        "id": "4z7XhoKU5FDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com relação à validação cruzada, responda a alternativa INCORRETA.\n",
        "\n",
        "4)\n",
        "\n",
        "a.\n",
        "A validação permite selecionar o modelo e o seus hiperparâmetros.\n",
        "\n",
        "\n",
        "b.\n",
        "Permite obter resultados mais robustos, pois reduz a variância do modelo.\n",
        "\n",
        "\n",
        "c.\n",
        "O método é aplicado ao conjunto de treinamento, obtido depois da separação em treinamento e teste.\n",
        "\n",
        "\n",
        "d.\n",
        "Para dados desbalanceados, recomenda-se usar o método com estratificação.\n",
        "\n",
        "\n",
        "e.\n",
        "O erro obtido na validação cruzada pode ser usado como medida de desempenho geral do modelo."
      ],
      "metadata": {
        "id": "50lOMigK5BBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. O erro obtido na validação cruzada pode ser usado como medida de desempenho geral do modelo.\n",
        "\n",
        "Na verdade, o erro obtido na validação cruzada não é usado diretamente como medida de desempenho geral do modelo. A validação cruzada é uma técnica para estimar o desempenho de um modelo em dados não vistos (como o conjunto de teste), mas não é uma medida final de desempenho. É útil para comparar diferentes modelos e hiperparâmetros e selecionar o melhor entre eles.\n",
        "\n",
        "Após escolher o modelo com base na validação cruzada, é comum treinar o modelo final com todos os dados de treinamento e então avaliar seu desempenho em um conjunto de teste separado."
      ],
      "metadata": {
        "id": "Jg4LB3mz5CDb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RpG8hcTr5La1"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}